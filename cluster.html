
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Running on a cluster &#8212; lcdb-wf 0.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Troubleshooting" href="troubleshooting.html" />
    <link rel="prev" title="Wrappers" href="wrappers.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">lcdb-wf</a></h1>



<p class="blurb">Customizable workflows for high-throughput sequencing analysis</p>






<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Initial setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="tests.html">Running the tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying <code class="docutils literal notranslate"><span class="pre">lcdb-wf</span></code> and staying up-to-date</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflows.html">Overview of workflows</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnaseq.html">RNA-seq workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="downstream-rnaseq.html">Downstream RNA-seq in R</a></li>
<li class="toctree-l1"><a class="reference internal" href="chipseq.html">ChIP-seq workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="external.html">“External” workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="figures.html">“Figures” workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="colocalization.html">Colocalization workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrappers.html">Wrappers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Running on a cluster</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#tmpdir-handling">TMPDIR handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clusterconfig-yaml-files"><code class="docutils literal notranslate"><span class="pre">clusterconfig.yaml</span></code> files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="autodoc.html">Module documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="developers.html">Developers</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="wrappers.html" title="previous chapter">Wrappers</a></li>
      <li>Next: <a href="troubleshooting.html" title="next chapter">Troubleshooting</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="running-on-a-cluster">
<span id="cluster"></span><h1>Running on a cluster<a class="headerlink" href="#running-on-a-cluster" title="Permalink to this headline">¶</a></h1>
<p>The example commands in <a class="reference internal" href="getting-started.html#getting-started"><span class="std std-ref">Initial setup</span></a> describe running Snakemake
locally. For larger data sets, you’ll want to run them on an HPC cluster.
Snakemake <a class="reference external" href="http://snakemake.readthedocs.io/en/latest/snakefiles/configuration.html">supports arbitrary cluster commands</a>,
making it easy to run these workflows on many different cluster environments.</p>
<p>Snakemake, and these workflows, are designed to decouple the code from the
configuration. If you are running the workflows on NIH’s Biowulf cluster, you
don’t need to change anything. If you are running on a different cluster, you
should inspect the following files:</p>
<ul class="simple">
<li><p><cite>include/WRAPPER_SLURM</cite> (see <span class="xref std std-ref">wrapper</span>)</p></li>
<li><p>the <cite>config/clusterconfig.yaml</cite> files in each workflow directory you will be
using (see <a class="reference internal" href="#clusterconfig"><span class="std std-ref">clusterconfig.yaml files</span></a>)</p></li>
<li><p><cite>lib/cluster_specific.py</cite>. This module currently has a single function that,
when called, will inspect the current environment variables and make any
necessary changes, returning the temp dir. Other cluster-specific code may go
here (see <cite>cluster_specific</cite>)</p></li>
</ul>
<p>The default configuration we provide is specific to the NIH Biowulf cluster.
To run a workflow on Biowulf, from the workflow directory (e.g.,
<code class="docutils literal notranslate"><span class="pre">workflows/rnaseq</span></code>, run the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sbatch</span> <span class="o">../../</span><span class="n">include</span><span class="o">/</span><span class="n">WRAPPER_SLURM</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">WRAPPER_SLURM</span></code> script submits the main Snakemake process on a separate
node to avoid any restrictions from running on the head node. That main
snakemake process then submits each rule separately to the cluster scheduler.
As configured in that script, we specify <code class="docutils literal notranslate"><span class="pre">config/clusterconfig.yaml</span></code> as
containing the rule-specific cluster arguments.</p>
<p>That script also contains this Snakemake arguments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">jobname</span> <span class="s2">&quot;s.</span><span class="si">{rulename}</span><span class="s2">.</span><span class="si">{jobid}</span><span class="s2">.sh&quot;</span> \
<span class="o">--</span><span class="n">cluster</span> <span class="s1">&#39;sbatch </span><span class="si">{cluster.prefix}</span><span class="s1"> --cpus-per-task=</span><span class="si">{threads}</span><span class="s1">  --output=logs/</span><span class="si">{rule}</span><span class="s1">.o.%j --error=logs/</span><span class="si">{rule}</span><span class="s1">.e.%j&#39;</span> \
</pre></div>
</div>
<p>This means that each job is named after the rule and job id (the <code class="docutils literal notranslate"><span class="pre">--jobname</span></code>
arg) and the stdout and stderr go to files in <code class="docutils literal notranslate"><span class="pre">logs</span></code> and are named after the
rule, followed by a <code class="docutils literal notranslate"><span class="pre">.o</span></code> or <code class="docutils literal notranslate"><span class="pre">.e</span></code>, followed by the cluster job ID (the
<code class="docutils literal notranslate"><span class="pre">--cluster</span></code> arg).</p>
<div class="section" id="tmpdir-handling">
<span id="cluster-specific"></span><h2>TMPDIR handling<a class="headerlink" href="#tmpdir-handling" title="Permalink to this headline">¶</a></h2>
<p>The top of each snakefile sets up a shell prefix that exports the TMPDIR
variable. The reason for this is that the NIH Biowulf cluster supports nodes
with temporary local storage in a directory named after the SLURM job ID. This
ID is not known ahead of time, but is stored in the <code class="docutils literal notranslate"><span class="pre">SLURM_JOBID</span></code> env var.</p>
<p>Since each rule executed on a cluster node calls the snakefile (see the job
scripts created by snakemake for more on this), we can look for the job ID and
set the tempdir appropriately. Upon setting <code class="docutils literal notranslate"><span class="pre">$TMPDIR</span></code>, the Python
<code class="docutils literal notranslate"><span class="pre">tempfile</span></code> module will use that directory to store temp files. Any wrappers
can additionally use <code class="docutils literal notranslate"><span class="pre">$TMPDIR</span></code> in shell commands and it will use this
directory.</p>
<p>Note that the default behavior – if the <code class="docutils literal notranslate"><span class="pre">SLURM_JOBID</span></code> env var is not set –
is to set <code class="docutils literal notranslate"><span class="pre">$TMPDIR</span></code> to the default temp directory as documented in Python’s
<a href="#id1"><span class="problematic" id="id2">`tempfile module
&lt; https://docs.python.org/3/library/tempfile.html#tempfile.gettempdir&gt;`_</span></a>.
However if you use these workflows on a different cluster, you may need to
provide a different function to return the job-specific temp directory.</p>
</div>
<div class="section" id="clusterconfig-yaml-files">
<span id="clusterconfig"></span><h2><code class="docutils literal notranslate"><span class="pre">clusterconfig.yaml</span></code> files<a class="headerlink" href="#clusterconfig-yaml-files" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://snakemake.readthedocs.io/en/stable/snakefiles/configuration.html#cluster-configuration">snakemake cluster configuration docs</a>
describe how to configure cluster-specific settings so that rules will run on
the correct size node when submitting batch jobs. This is not needed if you are
running the workflows locally, but you may need to edit the
<cite>config/clusterconfig.yaml</cite> file found in each workflow directory.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2017, Ryan Dale, Justin Fear.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/cluster.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>